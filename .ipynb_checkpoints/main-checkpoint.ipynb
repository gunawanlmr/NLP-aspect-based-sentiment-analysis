{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "from nltk.tag import hmm\n",
    "from sklearn.externals import joblib\n",
    "from nltk.tag.hmm  import HiddenMarkovModelTagger, HiddenMarkovModelTrainer\n",
    "from nltk.probability import LidstoneProbDist\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "import nltk\n",
    "import dill\n",
    "import pickle\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"lib/uuparser/barchybrid/src/\")\n",
    "import utils\n",
    "from arc_hybrid import ArcHybridLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS_DIR = 'models/id_gsd/'\n",
    "TAGGER_FILE_NAME = 'tagger.dill'\n",
    "PARAMS_FILE = MODELS_DIR + \"params.pickle\"\n",
    "PARSER_FILE=\"barchybrid.model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(MODELS_DIR + TAGGER_FILE_NAME, 'rb') as f:\n",
    "    hmm_tagger = dill.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from models/id_gsd/barchybrid.model\n"
     ]
    }
   ],
   "source": [
    "with open(PARAMS_FILE, 'r') as paramsfp:\n",
    "    words, w2i, pos, rels, cpos, langs, stored_opt, ch = pickle.load(paramsfp)\n",
    "    parser = ArcHybridLSTM(words, pos, rels, cpos, langs, w2i,\n",
    "                           ch, stored_opt)\n",
    "    model = os.path.join(MODELS_DIR, PARSER_FILE)\n",
    "    parser.Load(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PROCESS INDIVIDUAL REVIEW\n",
    "\n",
    "contoh review:\n",
    "\n",
    "sapi bakarnya enak banget harganya juga lumayan murah"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOOD_POSITIVE_ADJ = ['enak', 'banyk']\n",
    "FOOD_NEGATIVE_ADJ = ['mahal']\n",
    "\n",
    "PRICE_POSITIVE_ADJ = ['murah']\n",
    "PRICE_NEGATIVE_ADJ = ['mahal']\n",
    "\n",
    "SERVICE_POSITIVE_ADJ = ['murah']\n",
    "SERVICE_NEGATIVE_ADJ = ['mahal']\n",
    "\n",
    "AMBIENCE_POSITIVE_ADJ = ['murah']\n",
    "AMBIENCE_NEGATIVE_ADJ = ['mahal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sentences'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['Suka sama bebek ini karna dulu d ajak tmn makan di sini, ehh malah jd ketagihan sama dagingnya yg empuk dan sambel mentah nya yg dasyatttt Dulu tempatnya masih tenda, sekarang udh ada kiosnya, kursinya lumayan banyak ada toilet nya juga.. Kalo makan bebek ini selalu order dua bebek, nasi uduk, sate rempela, sambel mentah ekstra pedas dan es teh manis, sambel mentah nya bisa request pedasnya..']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "review = \"Suka sama bebek ini karna dulu d ajak tmn makan di sini, ehh malah jd ketagihan sama dagingnya yg empuk dan sambel mentah nya yg dasyatttt Dulu tempatnya masih tenda, sekarang udh ada kiosnya, kursinya lumayan banyak ada toilet nya juga.. Kalo makan bebek ini selalu order dua bebek, nasi uduk, sate rempela, sambel mentah ekstra pedas dan es teh manis, sambel mentah nya bisa request pedasnya..\"\n",
    "sentences = sent_tokenize(review)\n",
    "display('sentences', sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged = hmm_tagger.tag(review.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunkGram = r\"\"\"Chunk: {<NN*>}\"\"\"\n",
    "chunkParser = nltk.RegexpParser(chunkGram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunked = chunkParser.parse(tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Tree' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-82-f0eba290e7c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mprint\u001b[0m \u001b[0mchunked\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Tree' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "print chunked[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "point1 = [\"VBD\", \"VB\", \"VBG\", \"VBN\",\"VBP\", \"VBZ\", \"JJ\", \"JJR\", \"JJS\", \"RB\", \"RBR\", \"RBS\"]\n",
    "point2 = [\"JJ\", \"JJR\", \"JJS\", \"RB\", \"RBR\", \"RBS\"]\n",
    "verb = [\"VBD\", \"VB\", \"VBG\", \"VBN\",\"VBP\", \"VBZ\"]\n",
    "noun = [\"NN\", \"NNS\", \"NNP\", \"NNPS\", \"Z\"]\n",
    "adverb =[\"RB\", \"RBR\", \"RBS\"]\n",
    "adjective = [\"JJ\", \"JJR\", \"JJS\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def examine_polarity(sentence):\n",
    "    \"\"\"\n",
    "        Check negative positive word regarding food, price, service, and ambience aspect in particular sentence\n",
    "    \"\"\"\n",
    "    pol_food = pol_price = pol_service = pol_ambience = 0\n",
    "    \n",
    "    tagged_sentence = ' '.join(['{0}/{1}'.format(word, tag) for word, tag in hmm_tagger.tag(review.split())])\n",
    "    data = utils.read_conll_text(tagged_sentence)\n",
    "    pred = parser.Predict(data)\n",
    "    depedency_tree = list(pred)[0]\n",
    "    \n",
    "    for p in depedency_tree:\n",
    "        if p.pos == 'JJ':\n",
    "            print p\n",
    "            parent_id = p.pred_parent_id\n",
    "            offset = 5\n",
    "            while(parent_id != None and parent_id > 0):\n",
    "                parent = depedency_tree[parent_id]\n",
    "                if (parent.pos in noun):\n",
    "                    print parent\n",
    "                    break\n",
    "                parent_id = parent.pred_parent_id\n",
    "                offset -= 1\n",
    "    print \"\"\n",
    "    return pol_food, pol_price, pol_service, pol_ambience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading Suka/RB sama/JJ bebek/NN ini/PR karna/Z dulu/FW d/FW ajak/FW tmn/FW makan/VB di/IN sini,/FW ehh/FW malah/FW jd/FW ketagihan/FW sama/JJ dagingnya/Z yg/SC empuk/JJ dan/CC sambel/FW mentah/FW nya/FW yg/FW dasyatttt/FW Dulu/FW tempatnya/FW masih/MD tenda,/VB sekarang/NN udh/SC ada/VB kiosnya,/PRP kursinya/NEG lumayan/RB banyak/CD ada/VB toilet/NN nya/PRP juga../NEG Kalo/MD makan/VB bebek/NN ini/PR selalu/RB order/SYM dua/CD bebek,/FW nasi/FW uduk,/FW sate/FW rempela,/FW sambel/FW mentah/FW ekstra/FW pedas/FW dan/CC es/FW teh/FW manis,/FW sambel/FW mentah/JJ nya/PRP bisa/MD request/RB pedasnya../JJ\n",
      "Time: 0.12s\n",
      "2\tsama\t_\t_\tJJ\t_\t1\tcompound\t_\t_\n",
      "17\tsama\t_\t_\tJJ\t_\t16\tcompound\t_\t_\n",
      "5\tkarna\t_\t_\tZ\t_\t3\tdet\t_\t_\n",
      "20\tempuk\t_\t_\tJJ\t_\t19\tcompound\t_\t_\n",
      "18\tdagingnya\t_\t_\tZ\t_\t17\tcompound\t_\t_\n",
      "63\tmentah\t_\t_\tJJ\t_\t62\tcompound\t_\t_\n",
      "44\tbebek\t_\t_\tNN\t_\t43\tdet\t_\t_\n",
      "67\tpedasnya..\t_\t_\tJJ\t_\t66\tcompound\t_\t_\n",
      "44\tbebek\t_\t_\tNN\t_\t43\tdet\t_\t_\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for sentence in sentences:\n",
    "    pol_food, pol_price, pol_service, pol_ambience = examine_polarity(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tryim = load_model('model.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
