{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "from nltk.tag import hmm\n",
    "from sklearn.externals import joblib\n",
    "from nltk.tag.hmm  import HiddenMarkovModelTagger, HiddenMarkovModelTrainer\n",
    "from nltk.probability import LidstoneProbDist\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "import nltk\n",
    "import dill\n",
    "import pickle\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "import re\n",
    "import gensim\n",
    "import nltk\n",
    "import math\n",
    "import pickle\n",
    "from dataPreprocessing import getData\n",
    "\n",
    "sys.path.append(\"lib/uuparser/barchybrid/src/\")\n",
    "import utils\n",
    "from arc_hybrid import ArcHybridLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_list = ['dataset/training_text.csv', 'dataset/Indonesian_Tweets.tsv']\n",
    "\n",
    "def dataGetter(source_list):\n",
    "    corpus = []\n",
    "    for source in source_list:\n",
    "        corpus = corpus + getData(source)\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class similarity:\n",
    "    def __init__(self, source_list):\n",
    "        corpus = dataGetter(source_list)\n",
    "        self.model = self.getWord2Vec(corpus)\n",
    "        self.aspects = ['makanan', 'pelayanan', 'harga', 'suasana']\n",
    "        self.polarities = ['baik', 'buruk']\n",
    "        \n",
    "    def getWord2Vec(self, toFeed, dim=50):\n",
    "        return gensim.models.Word2Vec(toFeed, min_count=1,  size=dim)\n",
    "    \n",
    "    def most_similar_aspect(self, word):\n",
    "        most_similar = (0, \"\")\n",
    "        for aspect in self.aspects:\n",
    "            score = self.model.wv.similarity(word, aspect)\n",
    "            if score > most_similar[0]:\n",
    "                most_similar = (score, aspect)\n",
    "        return most_similar\n",
    "    \n",
    "    def most_similar_polarities(self, word):\n",
    "        most_similar = (0, \"\")\n",
    "        for polarity in self.polarities:\n",
    "            score = self.model.wv.similarity(word, polarity)\n",
    "            if score > most_similar[0]:\n",
    "                most_similar = (score, polarity)\n",
    "        return most_similar\n",
    "    \n",
    "    def most_similar_word_with_aspect(self, sentence, aspect):\n",
    "        most_similar = (0, \"\")\n",
    "        for word in sentence.split():\n",
    "            score = self.model.wv.similarity(word, aspect)\n",
    "            if score > most_similar[0]:\n",
    "                most_similar = (score, word)\n",
    "        return most_similar\n",
    "    \n",
    "def save_model(filename, obj):\n",
    "    with open(filename, 'wb') as handle:\n",
    "        pickle.dump(obj, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "            \n",
    "def load_model(filename):\n",
    "    with open(filename, 'rb') as handle:\n",
    "        model = pickle.load(handle)\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = None\n",
    "try:\n",
    "    sim = load_model('model.pickle')\n",
    "except:\n",
    "    sim = similarity(source_list)\n",
    "    save_model('model.pickle', sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS_DIR = 'models/id_gsd/'\n",
    "TAGGER_FILE_NAME = 'tagger.dill'\n",
    "PARAMS_FILE = MODELS_DIR + \"params.pickle\"\n",
    "PARSER_FILE=\"barchybrid.model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(MODELS_DIR + TAGGER_FILE_NAME, 'rb') as f:\n",
    "    hmm_tagger = dill.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from models/id_gsd/barchybrid.model\n"
     ]
    }
   ],
   "source": [
    "with open(PARAMS_FILE, 'r') as paramsfp:\n",
    "    words, w2i, pos, rels, cpos, langs, stored_opt, ch = pickle.load(paramsfp)\n",
    "    parser = ArcHybridLSTM(words, pos, rels, cpos, langs, w2i,\n",
    "                           ch, stored_opt)\n",
    "    model = os.path.join(MODELS_DIR, PARSER_FILE)\n",
    "    parser.Load(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PROCESS INDIVIDUAL REVIEW\n",
    "\n",
    "contoh review:\n",
    "\n",
    "sapi bakarnya enak banget harganya juga lumayan murah"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOOD_POSITIVE_ADJ = ['enak', 'banyak', 'lembut']\n",
    "FOOD_NEGATIVE_ADJ = ['pahit']\n",
    "\n",
    "PRICE_POSITIVE_ADJ = ['murah', 'banyak']\n",
    "PRICE_NEGATIVE_ADJ = ['mahal', 'sedikit']\n",
    "\n",
    "SERVICE_POSITIVE_ADJ = ['cepat', 'baik', 'bagus', 'ramah']\n",
    "SERVICE_NEGATIVE_ADJ = ['kasar', 'lambat']\n",
    "\n",
    "AMBIENCE_POSITIVE_ADJ = ['nyaman', 'adem']\n",
    "AMBIENCE_NEGATIVE_ADJ = ['berantakan', 'panas']\n",
    "\n",
    "MERGED = FOOD_POSITIVE_ADJ + FOOD_NEGATIVE_ADJ + PRICE_POSITIVE_ADJ + PRICE_NEGATIVE_ADJ + SERVICE_POSITIVE_ADJ + SERVICE_NEGATIVE_ADJ + AMBIENCE_POSITIVE_ADJ + AMBIENCE_NEGATIVE_ADJ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "review = \"Tadi gue first time lewat Beji pas lewat dpn cafe ini, gue lgsng trtarik buat dtg Karna baru bgt buka. Gue mesen beberapa makanan yaitu roti choco crunch , sossis and potato pke sauce bbq apa tau namanya lupa, sm pizza mie pake topping smoked beef. Gilak gue rasa utk servis msh hrs byk belajar deh, gak kyk td pelayannya gak peka. Masih kaku gt. Terus masa gue dah hampir 30menit lama gak ada satupun mknan yg dtg. Trs cwok gue manggil waittersnya nanya mknannya dah jd apa belum, dan mas2 nya blg \"\"maaf ya mas td kita bingung cari yg mesen\"\" buset deh trnyata bener meja sblah gue kyknya dah mulai bosen. Pelayannya pun terlihat pd masih kebingungan. So klo mnrt gue dri segi makanan sih lumayan, service dan prosedur pelayanannya sih yg mesti jd concern, kliatan bgt blm ready. Pdhal tempatnya dah keren, luas bgt. Interiornya keren. Smga bisa terus maju.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "point1 = [\"VBD\", \"VB\", \"VBG\", \"VBN\",\"VBP\", \"VBZ\", \"JJ\", \"JJR\", \"JJS\", \"RB\", \"RBR\", \"RBS\"]\n",
    "point2 = [\"JJ\", \"JJR\", \"JJS\", \"RB\", \"RBR\", \"RBS\"]\n",
    "verb = [\"VBD\", \"VB\", \"VBG\", \"VBN\",\"VBP\", \"VBZ\"]\n",
    "noun = [\"NN\", \"NNS\", \"NNP\", \"NNPS\", \"Z\"]\n",
    "adverb =[\"RB\", \"RBR\", \"RBS\"]\n",
    "adjective = [\"JJ\", \"JJR\", \"JJS\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "def examine_polarity(sentence):\n",
    "    \"\"\"\n",
    "        Check negative positive word regarding food, price, service, and ambience aspect in particular sentence\n",
    "    \"\"\"\n",
    "    polarities = {\n",
    "        'makanan': 0,\n",
    "        'harga': 0,\n",
    "        'pelayanan': 0,\n",
    "        'suasana': 0,      \n",
    "    }\n",
    "    \n",
    "    tagged_sentence = ' '.join(['{0}/{1}'.format(word, tag) for word, tag in hmm_tagger.tag(sentence.split())])\n",
    "    print tagged_sentence\n",
    "    for i, tagged_sentence in enumerate(tagged_sentence.split()):\n",
    "        word, tag = tagged_word.split('/')\n",
    "        print '{} - {}'.format(word, tag)\n",
    "        \n",
    "    data = utils.read_conll_text(tagged_sentence)\n",
    "    pred = parser.Predict(data)\n",
    "    depedency_tree = list(pred)[0]\n",
    "    \n",
    "    for p in depedency_tree:\n",
    "        if p.pos == 'JJ' or p.form in MERGED:\n",
    "            try:\n",
    "                pol = sim.most_similar_polarities(p.form)\n",
    "                weight = -1 if (pol[1] == 'buruk' and pol[0] > 0.5) else 1\n",
    "                parent_id = p.pred_parent_id\n",
    "                offset = 3\n",
    "                aspects = {\n",
    "                        'makanan': 0,\n",
    "                        'harga': 0,\n",
    "                        'pelayanan': 0,\n",
    "                        'suasana': 0\n",
    "                    }\n",
    "                while(parent_id != None and parent_id > 0 and offset > 0):\n",
    "                    parent = depedency_tree[parent_id]\n",
    "                    value, aspect = sim.most_similar_aspect(parent.form)\n",
    "                    aspects[aspect] += value\n",
    "                    parent_id = parent.pred_parent_id\n",
    "                    offset -= 1\n",
    "                s = sorted(aspects.items(), key=lambda x: x[1], reversed=True)\n",
    "                avg_aspect = aspects.keys()[0]\n",
    "                polarities[avg_aspect] += weight\n",
    "            except:\n",
    "                s = sorted(aspects.items(), key=lambda x: x[1], reverse=True)\n",
    "                avg_aspect = s[0][0]\n",
    "                polarities[avg_aspect] += weight\n",
    "    return polarities['makanan'], polarities['harga'], polarities['pelayanan'], polarities['suasana'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_review_polarities(review):\n",
    "    polarities = {\n",
    "        'makanan': 0,\n",
    "        'harga': 0,\n",
    "        'pelayanan': 0,\n",
    "        'suasana': 0,      \n",
    "    }\n",
    "    sentences = sent_tokenize(review)\n",
    "    for sentence in sentences:\n",
    "        pol_food, pol_price, pol_service, pol_ambience = examine_polarity(sentence)\n",
    "        polarities['makanan'] += pol_food\n",
    "        polarities['harga'] += pol_price\n",
    "        polarities['pelayanan'] += pol_service\n",
    "        polarities['suasana'] += pol_ambience\n",
    "        \n",
    "    for key, value in polarities.items():\n",
    "        if value > 0:\n",
    "            polarities[key] = 'POSITIVE'\n",
    "        elif value < 0:\n",
    "            polarities[key] = 'NEGATIVE'\n",
    "        else:\n",
    "            del polarities[key]\n",
    "    return polarities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suka/RB sama/JJ bebek/NN ini/PR karna/Z dulu/FW d/FW ajak/FW tmn/FW makan/VB di/IN sini,/FW ehh/FW malah/FW jd/FW ketagihan/FW sama/JJ dagingnya/Z yg/SC empuk/JJ dan/CC sambel/FW mentah/FW nya/FW yg/FW dasyatttt/FW Dulu/FW tempatnya/FW masih/MD tenda,/VB sekarang/NN udh/SC ada/VB kiosnya,/PRP kursinya/NEG lumayan/RB banyak/CD ada/VB toilet/NN nya/PRP juga../NEG Kalo/MD makan/VB bebek/NN ini/PR selalu/RB order/SYM dua/CD bebek,/FW nasi/FW uduk,/FW sate/FW rempela,/FW sambel/FW mentah/FW ekstra/FW pedas/FW dan/CC es/FW teh/FW manis,/FW sambel/FW mentah/JJ nya/PRP bisa/MD request/RB pedasnya../JJ\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "global name 'tagged_word' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-285-a03396845333>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mreview\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Suka sama bebek ini karna dulu d ajak tmn makan di sini, ehh malah jd ketagihan sama dagingnya yg empuk dan sambel mentah nya yg dasyatttt Dulu tempatnya masih tenda, sekarang udh ada kiosnya, kursinya lumayan banyak ada toilet nya juga.. Kalo makan bebek ini selalu order dua bebek, nasi uduk, sate rempela, sambel mentah ekstra pedas dan es teh manis, sambel mentah nya bisa request pedasnya..\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mextract_review_polarities\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreview\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-284-24fdf2e11842>\u001b[0m in \u001b[0;36mextract_review_polarities\u001b[0;34m(review)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msent_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreview\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mpol_food\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpol_price\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpol_service\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpol_ambience\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexamine_polarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mpolarities\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'makanan'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mpol_food\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mpolarities\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'harga'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mpol_price\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-283-ffa51cb66610>\u001b[0m in \u001b[0;36mexamine_polarity\u001b[0;34m(sentence)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0mtagged_sentence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtagged_sentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtagged_sentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtagged_word\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;32mprint\u001b[0m \u001b[0;34m'{} - {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: global name 'tagged_word' is not defined"
     ]
    }
   ],
   "source": [
    "review = \"Suka sama bebek ini karna dulu d ajak tmn makan di sini, ehh malah jd ketagihan sama dagingnya yg empuk dan sambel mentah nya yg dasyatttt Dulu tempatnya masih tenda, sekarang udh ada kiosnya, kursinya lumayan banyak ada toilet nya juga.. Kalo makan bebek ini selalu order dua bebek, nasi uduk, sate rempela, sambel mentah ekstra pedas dan es teh manis, sambel mentah nya bisa request pedasnya..\"\n",
    "extract_review_polarities(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = load_model('model.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = \"Suka sama bebek ini karna dulu d ajak tmn makan di sini, ehh malah jd ketagihan sama dagingnya yg empuk dan sambel mentah nya yg dasyatttt Dulu tempatnya masih tenda, sekarang udh ada kiosnya, kursinya lumayan banyak ada toilet nya juga.. Kalo makan bebek ini selalu order dua bebek, nasi uduk, sate rempela, sambel mentah ekstra pedas dan es teh manis, sambel mentah nya bisa request pedasnya..\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I/NNP love/FW the/FW concept./FW\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "global name 'tagged_word' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-288-27637f7934db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mreview_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreview\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0maspectEL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0met\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSubElement\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreview\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'aspects'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0maspects\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_review_polarities\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreview_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maspects\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0maspect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0met\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSubEelement\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maspectEL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'aspect'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-284-24fdf2e11842>\u001b[0m in \u001b[0;36mextract_review_polarities\u001b[0;34m(review)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msent_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreview\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mpol_food\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpol_price\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpol_service\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpol_ambience\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexamine_polarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mpolarities\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'makanan'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mpol_food\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mpolarities\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'harga'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mpol_price\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-283-ffa51cb66610>\u001b[0m in \u001b[0;36mexamine_polarity\u001b[0;34m(sentence)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0mtagged_sentence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtagged_sentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtagged_sentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtagged_word\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;32mprint\u001b[0m \u001b[0;34m'{} - {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: global name 'tagged_word' is not defined"
     ]
    }
   ],
   "source": [
    "import xml.etree.ElementTree as et\n",
    "from collections import OrderedDict\n",
    "\n",
    "doc = et.parse('dataset/data/training_set.xml')\n",
    "\n",
    "for review in doc.findall('review'):\n",
    "    rid = review.attrib.get('rid')\n",
    "    review_text = review.find('text').text\n",
    "    aspectEL = et.SubElement(review, 'aspects')\n",
    "    aspects = extract_review_polarities(str(review_text))\n",
    "    for key, value in aspects.items():\n",
    "        aspect = et.SubEelement(aspectEL, 'aspect')\n",
    "        if (key == 'makanan'):\n",
    "            aspect.set('category', 'FOOD')\n",
    "        if (key == 'harga'):\n",
    "            aspect.set('category', 'PRICE')\n",
    "        if (key == 'pelayanan'):\n",
    "            aspect.set('category', 'SERVICE')\n",
    "        if (key == 'suasana'):\n",
    "            aspect.set('category', 'AMBIENCE')\n",
    "        aspect.set('polarity', value)\n",
    "doc.write('result.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
