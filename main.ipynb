{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "from nltk.tag import hmm\n",
    "from sklearn.externals import joblib\n",
    "from nltk.tag.hmm  import HiddenMarkovModelTagger, HiddenMarkovModelTrainer\n",
    "from nltk.probability import LidstoneProbDist\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "import nltk\n",
    "import dill\n",
    "import pickle\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "import re\n",
    "import gensim\n",
    "import nltk\n",
    "import math\n",
    "import pickle\n",
    "from dataPreprocessing import getData\n",
    "\n",
    "sys.path.append(\"lib/uuparser/barchybrid/src/\")\n",
    "import utils\n",
    "from arc_hybrid import ArcHybridLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_list = ['dataset/training_text.csv', 'dataset/Indonesian_Tweets.tsv']\n",
    "\n",
    "def dataGetter(source_list):\n",
    "    corpus = []\n",
    "    for source in source_list:\n",
    "        corpus = corpus + getData(source)\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class similarity:\n",
    "    def __init__(self, source_list):\n",
    "        corpus = dataGetter(source_list)\n",
    "        self.model = self.getWord2Vec(corpus)\n",
    "        self.aspects = ['makanan', 'pelayanan', 'harga', 'suasana']\n",
    "        self.polarities = ['baik', 'buruk']\n",
    "        \n",
    "    def getWord2Vec(self, toFeed, dim=50):\n",
    "        return gensim.models.Word2Vec(toFeed, min_count=1,  size=dim)\n",
    "    \n",
    "    def most_similar_aspect(self, word):\n",
    "        most_similar = (0, \"\")\n",
    "        for aspect in self.aspects:\n",
    "            score = self.model.wv.similarity(word, aspect)\n",
    "            if score > most_similar[0]:\n",
    "                most_similar = (score, aspect)\n",
    "        return most_similar\n",
    "    \n",
    "    def most_similar_polarities(self, word):\n",
    "        most_similar = (0, \"\")\n",
    "        for polarity in self.polarities:\n",
    "            score = self.model.wv.similarity(word, polarity)\n",
    "            if score > most_similar[0]:\n",
    "                most_similar = (score, polarity)\n",
    "        return most_similar\n",
    "    \n",
    "    def most_similar_word_with_aspect(self, sentence, aspect):\n",
    "        most_similar = (0, \"\")\n",
    "        for word in sentence.split():\n",
    "            score = self.model.wv.similarity(word, aspect)\n",
    "            if score > most_similar[0]:\n",
    "                most_similar = (score, word)\n",
    "        return most_similar\n",
    "    \n",
    "def save_model(filename, obj):\n",
    "    with open(filename, 'wb') as handle:\n",
    "        pickle.dump(obj, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "            \n",
    "def load_model(filename):\n",
    "    with open(filename, 'rb') as handle:\n",
    "        model = pickle.load(handle)\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = None\n",
    "try:\n",
    "    sim = load_model('model.pickle')\n",
    "except:\n",
    "    sim = similarity(source_list)\n",
    "    save_model('model.pickle', sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS_DIR = 'models/id_gsd/'\n",
    "TAGGER_FILE_NAME = 'tagger.dill'\n",
    "PARAMS_FILE = MODELS_DIR + \"params.pickle\"\n",
    "PARSER_FILE=\"barchybrid.model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(MODELS_DIR + TAGGER_FILE_NAME, 'rb') as f:\n",
    "    hmm_tagger = dill.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from models/id_gsd/barchybrid.model\n"
     ]
    }
   ],
   "source": [
    "with open(PARAMS_FILE, 'r') as paramsfp:\n",
    "    words, w2i, pos, rels, cpos, langs, stored_opt, ch = pickle.load(paramsfp)\n",
    "    parser = ArcHybridLSTM(words, pos, rels, cpos, langs, w2i,\n",
    "                           ch, stored_opt)\n",
    "    model = os.path.join(MODELS_DIR, PARSER_FILE)\n",
    "    parser.Load(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PROCESS INDIVIDUAL REVIEW\n",
    "\n",
    "contoh review:\n",
    "\n",
    "sapi bakarnya enak banget harganya juga lumayan murah"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOOD_POSITIVE_ADJ = ['enak', 'banyak', 'lembut']\n",
    "FOOD_NEGATIVE_ADJ = ['pahit']\n",
    "\n",
    "PRICE_POSITIVE_ADJ = ['murah', 'banyak']\n",
    "PRICE_NEGATIVE_ADJ = ['mahal', 'sedikit']\n",
    "\n",
    "SERVICE_POSITIVE_ADJ = ['cepat', 'baik', 'bagus', 'ramah']\n",
    "SERVICE_NEGATIVE_ADJ = ['kasar', 'lambat']\n",
    "\n",
    "AMBIENCE_POSITIVE_ADJ = ['nyaman', 'adem']\n",
    "AMBIENCE_NEGATIVE_ADJ = ['berantakan', 'panas']\n",
    "\n",
    "MERGED = FOOD_POSITIVE_ADJ + FOOD_NEGATIVE_ADJ + PRICE_POSITIVE_ADJ + PRICE_NEGATIVE_ADJ + SERVICE_POSITIVE_ADJ + SERVICE_NEGATIVE_ADJ + AMBIENCE_POSITIVE_ADJ + AMBIENCE_NEGATIVE_ADJ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "review = \"Tadi gue first time lewat Beji pas lewat dpn cafe ini, gue lgsng trtarik buat dtg Karna baru bgt buka. Gue mesen beberapa makanan yaitu roti choco crunch , sossis and potato pke sauce bbq apa tau namanya lupa, sm pizza mie pake topping smoked beef. Gilak gue rasa utk servis msh hrs byk belajar deh, gak kyk td pelayannya gak peka. Masih kaku gt. Terus masa gue dah hampir 30menit lama gak ada satupun mknan yg dtg. Trs cwok gue manggil waittersnya nanya mknannya dah jd apa belum, dan mas2 nya blg \"\"maaf ya mas td kita bingung cari yg mesen\"\" buset deh trnyata bener meja sblah gue kyknya dah mulai bosen. Pelayannya pun terlihat pd masih kebingungan. So klo mnrt gue dri segi makanan sih lumayan, service dan prosedur pelayanannya sih yg mesti jd concern, kliatan bgt blm ready. Pdhal tempatnya dah keren, luas bgt. Interiornya keren. Smga bisa terus maju.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "point1 = [\"VBD\", \"VB\", \"VBG\", \"VBN\",\"VBP\", \"VBZ\", \"JJ\", \"JJR\", \"JJS\", \"RB\", \"RBR\", \"RBS\"]\n",
    "point2 = [\"JJ\", \"JJR\", \"JJS\", \"RB\", \"RBR\", \"RBS\"]\n",
    "verb = [\"VBD\", \"VB\", \"VBG\", \"VBN\",\"VBP\", \"VBZ\"]\n",
    "noun = [\"NN\", \"NNS\", \"NNP\", \"NNPS\", \"Z\"]\n",
    "adverb =[\"RB\", \"RBR\", \"RBS\"]\n",
    "adjective = [\"JJ\", \"JJR\", \"JJS\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "def examine_polarity(sentence):\n",
    "    \"\"\"\n",
    "        Check negative positive word regarding food, price, service, and ambience aspect in particular sentence\n",
    "    \"\"\"\n",
    "    polarities = {\n",
    "        'makanan': 0,\n",
    "        'harga': 0,\n",
    "        'pelayanan': 0,\n",
    "        'suasana': 0,      \n",
    "    }\n",
    "    \n",
    "    tagged_sentence = ' '.join(['{0}/{1}'.format(word, tag) for word, tag in hmm_tagger.tag(review.split())])\n",
    "    data = utils.read_conll_text(tagged_sentence)\n",
    "    pred = parser.Predict(data)\n",
    "    depedency_tree = list(pred)[0]\n",
    "    \n",
    "    for p in depedency_tree:\n",
    "        if p.pos == 'JJ' or p.form in MERGED:\n",
    "            try:\n",
    "                pol = sim.most_similar_polarities(p.form)\n",
    "                weight = -1 if (pol[1] == 'buruk' and pol[0] > 0.5) else 1\n",
    "                parent_id = p.pred_parent_id\n",
    "                offset = 3\n",
    "                aspects = {\n",
    "                        'makanan': 0,\n",
    "                        'harga': 0,\n",
    "                        'pelayanan': 0,\n",
    "                        'suasana': 0\n",
    "                    }\n",
    "                while(parent_id != None and parent_id > 0 and offset > 0):\n",
    "                    parent = depedency_tree[parent_id]\n",
    "                    value, aspect = sim.most_similar_aspect(parent.form)\n",
    "                    aspects[aspect] += value\n",
    "                    parent_id = parent.pred_parent_id\n",
    "                    offset -= 1\n",
    "                s = sorted(aspects.items(), key=lambda x: x[1], reversed=True)\n",
    "                avg_aspect = aspects.keys()[0]\n",
    "                polarities[avg_aspect] += weight\n",
    "            except:\n",
    "                s = sorted(aspects.items(), key=lambda x: x[1], reverse=True)\n",
    "                avg_aspect = s[0][0]\n",
    "                polarities[avg_aspect] += weight\n",
    "    return polarities['makanan'], polarities['harga'], polarities['pelayanan'], polarities['suasana'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_review_polarities(review):\n",
    "    polarities = {\n",
    "        'makanan': 0,\n",
    "        'harga': 0,\n",
    "        'pelayanan': 0,\n",
    "        'suasana': 0,      \n",
    "    }\n",
    "    sentences = sent_tokenize(review)\n",
    "    for sentence in sentences:\n",
    "        pol_food, pol_price, pol_service, pol_ambience = examine_polarity(sentence)\n",
    "        polarities['makanan'] += pol_food\n",
    "        polarities['harga'] += pol_price\n",
    "        polarities['pelayanan'] += pol_service\n",
    "        polarities['suasana'] += pol_ambience\n",
    "        \n",
    "    for key, value in polarities.items():\n",
    "        if value > 0:\n",
    "            polarities[key] = 'POSITIVE'\n",
    "        elif value < 0:\n",
    "            polarities[key] = 'NEGATIVE'\n",
    "        else:\n",
    "            del polarities[key]\n",
    "    return polarities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 0.2s\n",
      "Time: 0.16s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'harga': 'POSITIVE', 'makanan': 'POSITIVE', 'suasana': 'POSITIVE'}"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review = \"harga lumayan murah banget, Sengaja macet2an kesini cuman buat nyobain nasi goreng cakalang yang orang2 bilang enak. Dan emang beneran enak sih nasi gorengnya wkkw suasana nya juga enak buat makan ramai2 gitu.\"\n",
    "extract_review_polarities(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = load_model('model.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
